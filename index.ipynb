{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: 3D Gaussian Splatting\n",
    "\n",
    "Author: [Mukai (Tom Notch) Yu](https://tomnotch.com)\n",
    "\n",
    "Email: [mukaiy@andrew.cmu.edu](mailto:mukaiy@andrew.cmu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 3D Gaussian Splatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Perform Splatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![q1.1.5](Q1/output/q1.1.5_render.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Perform Forward Pass and Compute Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![progress](Q1/output/q1_training_progress.gif)\n",
    "\n",
    "\"wriggling gaussians\"\n",
    "\n",
    "![final](Q1/output/q1_training_final_renders.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation --- Mean PSNR: 28.489\n",
    "\n",
    "Evaluation --- Mean SSIM: 0.930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "parameters = [\n",
    "    {\"params\": [gaussians.pre_act_opacities], \"lr\": 0.05, \"name\": \"opacities\"},\n",
    "    {\"params\": [gaussians.pre_act_scales], \"lr\": 0.01, \"name\": \"scales\"},\n",
    "    {\"params\": [gaussians.colors], \"lr\": 0.05, \"name\": \"colors\"},\n",
    "    {\"params\": [gaussians.means], \"lr\": 0.001, \"name\": \"means\"},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1k iterations, took 19min 29s on A100-80G, final loss = 0.008, reached after 100 iterations so shouldn't take that many iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Rendering Using Spherical Harmonics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diffusion-guided Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SDS Loss + Image Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Q2/output/image/a_hamburger_no_guidance/output.png\" alt=\"Without guidance\" width=\"45%\"/>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; <!-- This is for adding space between the images -->\n",
    "  <img src=\"Q2/output/image/a_hamburger/output.png\" alt=\"With guidance\" width=\"45%\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <em>Without guidance (2000 iterations) a hamburger</em>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <em>With guidance (2000 iterations) a hamburger</em>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Q2/output/image/a_standing_corgi_dog_no_guidance/output.png\" alt=\"Without guidance\" width=\"45%\"/>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; <!-- This is for adding space between the images -->\n",
    "  <img src=\"Q2/output/image/a_standing_corgi_dog/output.png\" alt=\"With guidance\" width=\"45%\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <em>Without guidance (2000 iterations) a standing corgi dog</em>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <em>With guidance (2000 iterations) a standing corgi dog</em>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Q2/output/image/diffusion_no_guidance/output.png\" alt=\"Without guidance\" width=\"45%\"/>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; <!-- This is for adding space between the images -->\n",
    "  <img src=\"Q2/output/image/diffusion/output.png\" alt=\"With guidance\" width=\"45%\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <em>Without guidance (2000 iterations) diffusion</em>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <em>With guidance (2000 iterations) diffusion</em>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Q2/output/image/a_snake_poking_its_head_out_of_a_water_bottle_like_aquarius,_while_its_body_swirls_at_the_bottom_of_the_bottle_no_guidance/output.png\" alt=\"Without guidance\" width=\"45%\"/>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; <!-- This is for adding space between the images -->\n",
    "  <img src=\"Q2/output/image/a_snake_poking_its_head_out_of_a_water_bottle_like_aquarius,_while_its_body_swirls_at_the_bottom_of_the_bottle/output.png\" alt=\"With guidance\" width=\"45%\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <em>Without guidance (2000 iterations)</em>\n",
    "  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <em>With guidance (2000 iterations) (this is bull shit)</em>\n",
    "</p>\n",
    "\n",
    " a snake poking its head out of a water bottle like aquarius, while its body swirls at the bottom of the bottle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Texture Map Optimization for Mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hamburger](Q2/output/mesh/a_hamburger/final_mesh.gif)\n",
    "\n",
    "A hamburger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shire](Q2/output/mesh/a_village_like_Shire_in_the_lord_of_the_rings/final_mesh.gif)\n",
    "\n",
    "A village like Shire in the lord of the rings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think random viewpoint and light source would worsen result, because we cannot render or \"imprint\" the image onto the mesh from a particular viewpoint, we are only \"imprinting\" the dominant color in the end\n",
    "\n",
    "The geometry is fixed, and we do not encode viewpoint information in the text prompt when we generate latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 NeRF Optimization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
